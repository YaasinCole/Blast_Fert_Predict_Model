{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01e012-23c4-499a-9aa8-cbf0a740c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA PREPROCESSING\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('Simulated_Data.csv', sep=\";\" , skiprows=1 , decimal=\",\", encoding=\"utf-8\" , usecols=lambda col: col != 'Patient_ID')\n",
    "df.info()\n",
    "## Dropping null values from the dataset\n",
    "df = df.dropna(how=\"all\")\n",
    "df.isnull().sum()\n",
    "## Presenting data\n",
    "df.describe()\n",
    "\n",
    "## Checking for outliers\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "fig, axs = plt.subplots(len(numeric_df.columns), figsize=(10 , 5 *len(numeric_df.columns)))\n",
    "\n",
    "## Handle the case where there is only one column\n",
    "if len(numeric_df.columns) == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "i = 0\n",
    "for i, col in enumerate(numeric_df.columns):\n",
    "    axs[i].boxplot(numeric_df[col].dropna(), vert=False)\n",
    "    axs[i].set_title(col)\n",
    "    i+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## After the above runs, we have only two outliers within Total_Sperm_Count (million)  \n",
    "# The approach here is to keep these outliers and see what happens if it skews the model we will either \n",
    "# remove or cap them to the nearest non-outlier value\n",
    "\n",
    "## In the below, we are checking which features correlate with each other\n",
    "corr = numeric_df.corr()\n",
    "plt.figure(figsize=(18, 15), dpi=130)\n",
    "sns.heatmap(numeric_df.corr(), annot=True, fmt= '.2f')\n",
    "plt.savefig(\"correlation_heatmap.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "##Based on the heatmap above, the first test would be to keep all features \n",
    "#Second test we're going to run is dropping one of the features\n",
    "#that are correlated to non-target variable features \n",
    "#This is done before we do any other column manipulation \n",
    "\n",
    "###columns_to_drop = df.drop(columns=[\"Immotile_Sperm (%)\"])\n",
    "\n",
    "## Based on the above heatmap, we can see that there aren't any strong correlations \n",
    "# between any of the features and the target values Fert and Blast, \n",
    "\n",
    "#after the above we then separate the targets from input features \n",
    "x = df.drop(columns=[\"Fertilization Rate (%)\" , \"Blastulation_Rate (%)\"])\n",
    "y = df[[\"Fertilization Rate (%)\",\"Blastulation_Rate (%)\"]]\n",
    "\n",
    "## In the below we encode our categorical columns \n",
    "le_col= {}\n",
    "for col in x.columns:\n",
    "    if x[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        x[col] = le.fit_transform(x[col].astype(str))\n",
    "        le_col[col] = le\n",
    "\n",
    "## Convert encoded columns to dataframes to inspect \n",
    "# Making sure all the data is correct and no nulls for input features \n",
    "encoded_df = x.copy()\n",
    "encoded_df.head()\n",
    "print(encoded_df.dtypes)\n",
    "print(encoded_df.describe())\n",
    "print(encoded_df.isnull().sum())\n",
    "\n",
    "## Making sure target variables are correct with no nulls \n",
    "print(y.head())          # sample values\n",
    "print(y.dtypes)          # ensure numeric\n",
    "print(y.nunique())\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eabc3a10-1365-43f0-b61b-08e626ea2665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fertilization distribution:\n",
      "-1     28\n",
      " 0    245\n",
      " 1    659\n",
      " 2    568\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Current blastulation distribution:\n",
      "-1     22\n",
      " 0    488\n",
      " 1    509\n",
      " 2    481\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After re-binning:\n",
      "Fertilization distribution:\n",
      "-1     28\n",
      " 0    245\n",
      " 1    659\n",
      " 2    568\n",
      "Name: count, dtype: int64\n",
      "Number of fertilization classes: 4\n",
      "\n",
      "Blastulation distribution:\n",
      "-1     22\n",
      " 0    488\n",
      " 1    509\n",
      " 2    481\n",
      "Name: count, dtype: int64\n",
      "Number of blastulation classes: 4\n"
     ]
    }
   ],
   "source": [
    "## Binning the target variables for classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##In the below we define the edges for the classification and make them equal widths\n",
    "# the below can change based on domain knowledge \n",
    "fert_bin = [40,50,76,100] # Low: 40-50% Medium: 50-70% High: 70-100%\n",
    "blast_bin = [30,50,70,100]  # Low: 0-33% Medium: 33-66% High: 66-100%\n",
    "\n",
    "#Creating the labels for our classification problem \n",
    "fert_labels = ['Low','Meduim','High']\n",
    "blast_labels = ['Low', 'Meduim','High']\n",
    "\n",
    "# Binning the target variables\n",
    "y_fert_binned = pd.cut(y[\"Fertilization Rate (%)\"] , bins=fert_bin , labels=fert_labels, include_lowest=True)\n",
    "y_blast_binned = pd.cut(y[\"Blastulation_Rate (%)\"] , bins=blast_bin , labels=blast_labels, include_lowest=True)\n",
    "\n",
    "# Convert to categorical codes for the neural network \n",
    "y_fert_codes = y_fert_binned.cat.codes\n",
    "y_blast_codes = y_blast_binned.cat.codes\n",
    "\n",
    "# NOW check the distributions (after they're defined)\n",
    "print(\"Current fertilization distribution:\")\n",
    "print(y_fert_codes.value_counts().sort_index())\n",
    "\n",
    "print(\"\\nCurrent blastulation distribution:\")\n",
    "print(y_blast_codes.value_counts().sort_index())\n",
    "\n",
    "print(\"\\nAfter re-binning:\")\n",
    "print(\"Fertilization distribution:\")\n",
    "print(y_fert_codes.value_counts().sort_index())\n",
    "print(\"Number of fertilization classes:\", len(y_fert_codes.unique()))\n",
    "\n",
    "print(\"\\nBlastulation distribution:\")\n",
    "print(y_blast_codes.value_counts().sort_index())\n",
    "print(\"Number of blastulation classes:\", len(y_blast_codes.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3f7de1d-ce9a-4ef8-a7aa-19abd2887dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes after splitting:\n",
      "x_train shape: (672, 39)\n",
      "x_val shape: (168, 39)\n",
      "x_test shape: (360, 39)\n",
      "x_holdout shape: (300, 39)\n",
      "\n",
      "Fertilization - Train distribution: [  0 294 378]\n",
      "Fertilization - Validation distribution: [ 0 73 95]\n",
      "Fertilization - Test distribution: [  0 158 202]\n",
      "Fertilization - Holdout distribution: [  0 131 169]\n",
      "\n",
      "Blastulation - Train distribution: [ 46 368 258]\n",
      "Blastulation - Validation distribution: [10 92 66]\n",
      "Blastulation - Test distribution: [ 20 201 139]\n",
      "Blastulation - Holdout distribution: [ 16 174 110]\n"
     ]
    }
   ],
   "source": [
    "#SPLITTING UP DATA \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. FIRST SPLIT: Create temp and holdout sets\n",
    "x_temp, x_holdout, y_fert_temp, y_fert_holdout, y_blast_temp, y_blast_holdout = train_test_split(\n",
    "    encoded_df, y_fert_codes, y_blast_codes, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_fert_codes  # Stratify on one target (both should have similar distributions)\n",
    ")\n",
    "\n",
    "# 2. SECOND SPLIT: Create train and test sets from temp\n",
    "x_train, x_test, y_fert_train, y_fert_test, y_blast_train, y_blast_test = train_test_split(\n",
    "    x_temp, y_fert_temp, y_blast_temp,\n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y_fert_temp\n",
    ")\n",
    "\n",
    "# 3. THIRD SPLIT: Create train and validation sets from train\n",
    "x_train, x_val, y_fert_train, y_fert_val, y_blast_train, y_blast_val = train_test_split(\n",
    "    x_train, y_fert_train, y_blast_train,\n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_fert_train\n",
    ")\n",
    "\n",
    "print(\"Data shapes after splitting:\")\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_val shape:\", x_val.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"x_holdout shape:\", x_holdout.shape)\n",
    "\n",
    "#Checking the distribution of data\n",
    "print(\"\\nFertilization - Train distribution:\", np.bincount(y_fert_train))\n",
    "print(\"Fertilization - Validation distribution:\", np.bincount(y_fert_val))\n",
    "print(\"Fertilization - Test distribution:\", np.bincount(y_fert_test))\n",
    "print(\"Fertilization - Holdout distribution:\", np.bincount(y_fert_holdout))\n",
    "\n",
    "print(\"\\nBlastulation - Train distribution:\", np.bincount(y_blast_train))\n",
    "print(\"Blastulation - Validation distribution:\", np.bincount(y_blast_val))\n",
    "print(\"Blastulation - Test distribution:\", np.bincount(y_blast_test))\n",
    "print(\"Blastulation - Holdout distribution:\", np.bincount(y_blast_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720884d-4d9a-40fd-89c0-3e311ade516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Converting Panda series to numpy arrays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y_fert_train = y_fert_train.to_numpy().astype('int32')\n",
    "y_fert_val   = y_fert_val.to_numpy().astype('int32')\n",
    "y_fert_test  = y_fert_test.to_numpy().astype('int32')\n",
    "y_fert_holdout = y_fert_holdout.to_numpy().astype('int32')\n",
    "\n",
    "y_blast_train = y_blast_train.to_numpy().astype('int32')\n",
    "y_blast_val   = y_blast_val.to_numpy().astype('int32')\n",
    "y_blast_test  = y_blast_test.to_numpy().astype('int32')\n",
    "y_blast_holdout = y_blast_holdout.to_numpy().astype('int32')\n",
    "\n",
    "y_fert_train = y_fert_train - y_fert_train.min()\n",
    "y_fert_val   = y_fert_val - y_fert_val.min()\n",
    "\n",
    "y_blast_train = y_blast_train - y_blast_train.min()\n",
    "y_blast_val   = y_blast_val - y_blast_val.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76cfb70-2d2d-4c4a-90ed-9c3326995f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SCALING MY DATA \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## Initialising standard Scaler and scaling our input features for model training\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_holdout_scaled = scaler.transform(x_holdout)\n",
    "\n",
    "## Visualising data before and after Scaling \n",
    "x_train_scaled_df = pd.DataFrame(x_train_scaled, columns=x_train.columns)\n",
    "print(\"Before Scaling:\\n\", x_train.head())\n",
    "print(\"\\nAfter Scaling:\\n\", x_train_scaled_df.head())\n",
    "\n",
    "assert x_train_scaled.shape[0] == y_fert_train.shape[0] == y_blast_train.shape[0]\n",
    "assert x_val_scaled.shape[0] == y_fert_val.shape[0] == y_blast_val.shape[0]\n",
    "\n",
    "print(\"âœ“ All data shapes match!\")\n",
    "\n",
    "# Plotting 1 Feature to test Scaling\n",
    "feature = \"Sperm_Morphology (%)\"\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(x_train[feature] , bins=30)\n",
    "plt.title(f\"{feature} Before Scaling\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(x_train_scaled_df[feature], bins=30)\n",
    "plt.title(f\"{feature} After Scaling\")\n",
    "plt.show()\n",
    "\n",
    "print('x_train_scaled shape: ', x_train_scaled.shape)\n",
    "print('y_train_scaled shape: ', y_fert_train.shape)\n",
    "print('y_train_scaled shape: ', y_blast_train.shape)\n",
    "print(y_fert_train.shape, y_fert_train[:10], y_fert_train.dtype)\n",
    "print(y_blast_train.shape, y_blast_train[:10], y_blast_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998c0a7-e88a-4523-ab9d-00c98a079325",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling class Imbalance \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "fert_class_weights = compute_class_weight(\n",
    "    'balanced', \n",
    "    classes=np.unique(y_fert_train),\n",
    "    y=y_fert_train\n",
    ")\n",
    "blast_class_weights = compute_class_weight(\n",
    "    'balanced', \n",
    "    classes=np.unique(y_blast_train),\n",
    "    y=y_blast_train\n",
    ")\n",
    "\n",
    "fert_class_weight_dict = dict(enumerate(fert_class_weights))\n",
    "blast_class_weight_dict = dict(enumerate(blast_class_weights))\n",
    "\n",
    "print(\"Fertilization class weights:\", fert_class_weight_dict)\n",
    "print(\"Blastulation class weights:\", blast_class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f537fc-5ca2-4c6d-9575-1064ef2a0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD NEURAL NETWORK \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers, Sequential, optimizers\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.metrics import classification_report, confusion_matrix , roc_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#Clear any previous sessions \n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def create_classification_model(input_dim, model_name, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,) , name=f'{model_name}_input'), \n",
    "        layers.Dense(64, activation='relu', name=f'{model_name}_hidden1'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32 , activation='relu', name=f'{model_name}_hidden2' ),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation='softmax', name=f'{model_name}_output')\n",
    "])\n",
    "    model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model \n",
    "\n",
    "# Get number of classes\n",
    "num_fert_classes = len(np.unique(y_fert_train))\n",
    "num_blast_classes = len(np.unique(y_blast_train))\n",
    "\n",
    "print(f\"Number of fertilization classes: {num_fert_classes}\")\n",
    "print(f\"Number of blastulation classes: {num_blast_classes}\")\n",
    "\n",
    "#Setting the training data to the input for our MLP model,\n",
    "input_dim = x_train_scaled.shape[1]\n",
    "\n",
    "fert_model = create_classification_model(input_dim, \"fert\", num_fert_classes)\n",
    "blast_model = create_classification_model(input_dim, \"blast\", num_blast_classes)\n",
    "\n",
    "#Outputting what the model looks like and what is going to be used in training\n",
    "print(\"Fertilization Model Summary:\")\n",
    "fert_model.summary()\n",
    "print(\"\\nBlastulation Model Summary:\")\n",
    "blast_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218dad7-0cb0-4962-b2dc-02eb5f6b5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "##Implementing EarlyStopping and ModelCheckpoint\n",
    "# For us to save the best model and stop the model when it stops improving\n",
    "fert_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('best_fert_model.keras', save_best_only=True, monitor='val_loss'),\n",
    "]\n",
    "\n",
    "blast_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('best_blast_model.keras', save_best_only=True, monitor='val_loss')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3624a834-04a9-4a39-a38a-0b40541c1d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training the models \n",
    "\n",
    "print(\"Training Fertilization Model...\")\n",
    "fert_history = fert_model.fit(\n",
    "    x_train_scaled, y_fert_train,\n",
    "    validation_data=(x_val_scaled, y_fert_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    class_weight=fert_class_weight_dict,\n",
    "    callbacks=fert_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Blastulation Model...\")\n",
    "blast_history = blast_model.fit(\n",
    "    x_train_scaled, y_blast_train,\n",
    "    validation_data=(x_val_scaled, y_blast_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    class_weight=blast_class_weight_dict,\n",
    "    callbacks=blast_callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285e16a-f685-4df7-8367-74b60e2fd3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b8656-b8b8-4514-b214-5acc2bb76f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
